{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "thOKpwcM8_za"
   },
   "source": [
    "# Boiling Point of Compounds\n",
    "Based on:\n",
    " 1. S.-Y. Kim, I. Jeon and S.-J. Kang, \"Integrating Data Science and Machine Learning to Chemistry Education: Predicting Classification and Boiling Point of Compounds\", J. Chem. Educ., 101, 1771–1776 (2024). [doi:10.1021/acs.jchemed.3c01040](doi.org/10.1021/acs.jchemed.3c01040)\n",
    " 2. A. Géron, Hands-on machine learning with Scikit-Learn, Keras and TensorFlow: concepts, tools, and techniques to build intelligent systems, Third edition (2023) ISBN: 9781098125974\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QMCXVXDE8_zj"
   },
   "outputs": [],
   "source": [
    "from pylab import *\n",
    "import pandas as pd\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eA2DdL1V8_z8"
   },
   "outputs": [],
   "source": [
    "sklearn.set_config(display='diagram')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aoy2Hv6j8_zn"
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c7t995EI8_zo"
   },
   "outputs": [],
   "source": [
    "def plot_fun(bps, bp_predictions, t=None):\n",
    "    plot(bps, bp_predictions,'o')\n",
    "    plot(bps,bps)\n",
    "    axis('square')\n",
    "    xlabel('Boiling Point')\n",
    "    ylabel('Predicted Boiling Point')\n",
    "    title(t)\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hxYVyAFG8_zy"
   },
   "outputs": [],
   "source": [
    "def split_data_with_id_hash(data, test_ratio, id_column):\n",
    "\n",
    "    from zlib import crc32\n",
    "\n",
    "    def is_id_in_test_set(identifier, test_ratio):\n",
    "      return crc32(np.int64(identifier)) < test_ratio * 2**32\n",
    "\n",
    "    ids = data[id_column]\n",
    "    in_test_set = ids.apply(lambda id_: is_id_in_test_set(id_, test_ratio))\n",
    "    return data.loc[~in_test_set], data.loc[in_test_set]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iIfL7lBm8_zp"
   },
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "id": "JaFm2eWo8_zq",
    "outputId": "8e5caf2e-ed5c-40c4-b418-93fdca96c5c4"
   },
   "outputs": [],
   "source": [
    "data_url = 'https://raw.githubusercontent.com/woldr001/AIChE_Workshop_MSU/refs/heads/main/boiling_point_data.csv'\n",
    "compounds = pd.read_csv(data_url)\n",
    "compounds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ubrpVV1g8_zy"
   },
   "source": [
    "## Training Set and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qsk9S9_28_zz"
   },
   "outputs": [],
   "source": [
    "compounds = compounds.reset_index()\n",
    "train_set, test_set = split_data_with_id_hash(compounds, 0.2, \"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QaJLccNl8_z0",
    "outputId": "63623ce7-8548-4c56-bc39-b78322b63d72"
   },
   "outputs": [],
   "source": [
    "len(train_set), len(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jj1m9Shb8_z0"
   },
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hkXaapf88_z1"
   },
   "source": [
    "### Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 720
    },
    "id": "i9g_MZd38_z1",
    "outputId": "2dc49f83-10d0-45eb-e859-3e73b2ed1557"
   },
   "outputs": [],
   "source": [
    "plt.rc('font', size=14)\n",
    "plt.rc('axes', labelsize=14, titlesize=14)\n",
    "plt.rc('legend', fontsize=14)\n",
    "plt.rc('xtick', labelsize=10)\n",
    "plt.rc('ytick', labelsize=10)\n",
    "\n",
    "train_set.hist(bins=50, figsize=(12, 8))\n",
    "tight_layout()\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ujCIKver8_z2"
   },
   "source": [
    "### Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "L7CIEdlD8_z2",
    "outputId": "c375a4d0-a4e0-4962-bc3d-07a2b546dc67"
   },
   "outputs": [],
   "source": [
    "cols = ['BoilingPoint', 'mw', 'polararea', 'heavycnt',\n",
    "       'hbondacc', 'C number', 'N number', 'O number',\n",
    "       'Side chain number', 'Double bond number', 'Triple bond number']\n",
    "corr_matrix = train_set[cols].corr()\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NUKuhFDe8_z3"
   },
   "source": [
    "### Scatter Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 735
    },
    "id": "CMf6uZxA8_z3",
    "outputId": "b1ecf48f-0f72-4d0d-9d36-0f451cce138b"
   },
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "cols = ['BoilingPoint', 'mw', 'polararea', 'heavycnt',\n",
    "        'C number', 'N number', 'O number',\n",
    "       'Side chain number', 'Double bond number',]\n",
    "scatters = scatter_matrix(train_set[cols], figsize=(12, 8))\n",
    "for axs in scatters:\n",
    "    axs[0].yaxis.label.set_rotation(45)\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ya9ux4qK8_z4"
   },
   "source": [
    "## Prepare for ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gVBiQ-TU8_z4"
   },
   "source": [
    "### Define Labels\n",
    "Here we'll use the boiling points as labels. We'll also drop that data from the training set so that it won't be used as a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AEg4Z_Ch8_z5"
   },
   "outputs": [],
   "source": [
    "compounds=train_set.drop('BoilingPoint', axis=1)\n",
    "bps = train_set['BoilingPoint'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rei7C0q28_z5"
   },
   "source": [
    "### Encode Category Features\n",
    "To make the text feature \"Classify1\" more quantitative, use **\"One Hot\" encoding**, which adds columns to the data set where a \"1\" in the correct column indicates the category of the molecule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "id": "Z-sfGEqE8_z5",
    "outputId": "aa7ba991-9896-4250-813e-dbde10e91358"
   },
   "outputs": [],
   "source": [
    "compounds_category = compounds[[\"Classify1\"]]\n",
    "compounds_category.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S9TY-Jzq8_z6",
    "outputId": "ba1801a6-198e-4eb4-c537-38815015d883"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "cat_encoder = OneHotEncoder(sparse_output=False)\n",
    "compounds_cat_1hot = cat_encoder.fit_transform(compounds_category)\n",
    "compounds_cat_1hot[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Izowbe1Y8_z6",
    "outputId": "4dd4dff0-bfc3-426a-cbc8-6b3f11bbf4e5"
   },
   "outputs": [],
   "source": [
    "cat_encoder.categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cHLJrQ-r8_z7"
   },
   "source": [
    "### Scale Numerical Features\n",
    "Numerical features like MW often have to be modified for machine learning.  We'll use two common approaches:\n",
    " - `SimpleImputer` will be used to add missing values with the *average* of that feature. Note that there aren't any missing values here, so this step actually does nothing for this data.\n",
    " - `StandardScaler` changes the numerical range of all numerical features to between -1 and 1. This normalization is preferred for many models especially neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OKVzP6EQ8_z8"
   },
   "source": [
    "### Create Pipelines\n",
    "We'll put all of our feature prep in a pipeline. We'll start by making a numerical pipeline called `num_pipeline` that combines `SimpleImputer` and `StandardScaler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "POL-3Gv08_z8",
    "outputId": "41dac68c-b4a2-420b-ebd5-3a92d1a6a21b"
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "num_pipeline = make_pipeline(SimpleImputer(strategy=\"median\"), StandardScaler())\n",
    "\n",
    "num_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Then we make a similar pipeline for categories called `cat_pipeline` using `SimpleImputer` and `Standard Scaler`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_pipeline = make_pipeline(\n",
    "  SimpleImputer(strategy=\"most_frequent\"),\n",
    "  OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "\n",
    "cat_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Then we combine the numerical and category pipelines into a single pipeline called `preprocessing`.  Here we specify which numerical and category features to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "id": "0UoN_dPf8_z9",
    "outputId": "d1aec4dd-0aa4-454f-f850-f35a35923ba7"
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "num_features = ['mw', 'polararea', 'heavycnt',\n",
    "       'hbondacc', 'C number', 'N number', 'O number',\n",
    "       'Side chain number', 'Double bond number', 'Triple bond number']\n",
    "\n",
    "cat_features = [\"Classify1\"]\n",
    "\n",
    "preprocessing = ColumnTransformer([\n",
    "  (\"num\", num_pipeline, num_features),\n",
    "  (\"cat\", cat_pipeline, cat_features),\n",
    "])\n",
    "\n",
    "preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "This is what it looks like when we apply `preprocessing` to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B-RzG7B98_z-",
    "outputId": "5a288348-887c-4109-92e7-b57fafe3cb02"
   },
   "outputs": [],
   "source": [
    "compounds_prepared = preprocessing.fit_transform(compounds)\n",
    "compounds_prepared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Even though this is just an array of numbers, we can still get our feature names back:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lFItCm1S8_z-",
    "outputId": "a1d5f89f-4de9-4f9f-9b8d-3fb638adbb4c"
   },
   "outputs": [],
   "source": [
    "preprocessing.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tg-nZwYa8_z-"
   },
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a Linear Regression model obtains the best fit linear function of all numerical features according to the formula:\n",
    "\n",
    "$$ \\hat{y}=\\theta_0+\\theta_1 x_1+\\theta_2 x_2+\\cdots+\\theta_n x_n $$\n",
    "\n",
    "This model is mostly equivalent to linear least squares curve fitting approaches in MATLAB and `scipy`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "We combine `preprocessing` with `LinearRegression` into a new pipeline, `lin_reg`. Then we actually fit the data to `bps` using the `fit` method of our new pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "id": "aogeaTvd8_0K",
    "outputId": "f13312bb-2e75-4b43-c762-395819de9bdf"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = make_pipeline(preprocessing, LinearRegression())\n",
    "lin_reg.fit(compounds, bps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Now we can predict boiling points! We apply the `predict` method of the pipeline to `compounds`, and compare the first five results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zC4e501f8_0L",
    "outputId": "2e702778-f873-40a4-de9a-3a6297d8614c"
   },
   "outputs": [],
   "source": [
    "bp_predictions = lin_reg.predict(compounds)\n",
    "bp_predictions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 254
    },
    "id": "Ch8XUlyP8_0L",
    "outputId": "20e075de-da1d-49fb-ac79-5f176fb8f38c"
   },
   "outputs": [],
   "source": [
    "bps.iloc[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure of Merit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To quantify these differences, we'll use the root-mean-squared error, or RMSE, defined by:\n",
    "$$ \\operatorname{RMSE}(\\mathbf{X}, h)=\\sqrt{\\frac{1}{m} \\sum_{i=1}^m\\left(h\\left(\\mathbf{y}^{(i)}\\right)-y_{pred}^{(i)}\\right)^2} $$\n",
    "\n",
    "where $m$ is the number of data points, $y$ is the training labels (`bps`) and $y_{pred}$ is the predicted labels (`bp_predictions`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eZ7LGgFx8_0M",
    "outputId": "bd2b9fdf-ad30-44fe-b20c-61efdda23525"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import root_mean_squared_error\n",
    "lin_rmse = root_mean_squared_error(bps, bp_predictions)\n",
    "print(f'The RMSE error for the Linear Model is {lin_rmse:.2f} degrees')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare the labels and predictions by plotting. In this plot, an ideal fit has all of the blue dots on the orange line. Not a good look for the linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 499
    },
    "id": "cY4GGOEv8_0N",
    "outputId": "2ce4c5f4-0e09-4f8c-97c3-480b4df4a42b"
   },
   "outputs": [],
   "source": [
    "plot_fun(bps, bp_predictions, 'Linear Regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tELdRw0I8_0O"
   },
   "source": [
    "### Cross-Validation\n",
    "We can test these results for *overfitting* by making temporary test sets with a portion of our training data. Here, we use 10% of the training data as a test set. We can actually do this 10 different times with different portions of the training data and then look at statistics.  \n",
    "\n",
    "**If the RMSE of the full training set is much less than the average RMSE from cross-validation, we have overfitted our data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YVnP3CiP8_0O"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "lin_rmses = -cross_val_score(lin_reg, compounds, bps,\n",
    "                            scoring=\"neg_root_mean_squared_error\", cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DyjfPO668_0P",
    "outputId": "491fb2f7-6417-4b67-c458-0c0ea6054f6c"
   },
   "outputs": [],
   "source": [
    "lin_rmses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "id": "ako-nWUe8_0P",
    "outputId": "31d59b2c-0c1f-4545-ccf4-4a4895c2f34b"
   },
   "outputs": [],
   "source": [
    "pd.Series(lin_rmses).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "The linear model does not seem to overfit the data, but can we get a better fit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "rbXXDB298_0Q",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "A Decision Tree model determines result based on a series of decisions. Here is an example decision tree for a 1D model:\n",
    "\n",
    "![decision_tree.jpeg](http://www.egr.msu.edu/~scb/downloads/decision_tree.jpeg)\n",
    "\n",
    "As can be seen, the more layers of decision tree that are included, the more predictions are possible and the better the fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "id": "6PsOIMf_8_0R",
    "outputId": "6ccdfe80-a6a6-4dc0-88a3-a47849cef606"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg = make_pipeline(preprocessing, DecisionTreeRegressor(random_state=42))\n",
    "tree_reg.fit(compounds, bps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qil2NO6_8_0S",
    "outputId": "85ad268f-d9f0-42e4-9833-b9866462637a"
   },
   "outputs": [],
   "source": [
    "bp_predictions = tree_reg.predict(compounds)\n",
    "tree_rmse = root_mean_squared_error(bps, bp_predictions)\n",
    "tree_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 499
    },
    "id": "OLUkdhMl8_0S",
    "outputId": "46f7e851-0349-4608-be83-79e3e4ea3946"
   },
   "outputs": [],
   "source": [
    "plot_fun(bps, bp_predictions, 'Decision Tree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6hEoZnGj8_0T"
   },
   "source": [
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TV3I9hMg8_0U"
   },
   "outputs": [],
   "source": [
    "tree_rmses = -cross_val_score(tree_reg, compounds, bps,\n",
    "                            scoring=\"neg_root_mean_squared_error\", cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SO9YBV7T8_0V",
    "outputId": "bced13e6-1f28-427b-d10d-74d11a825b2f"
   },
   "outputs": [],
   "source": [
    "tree_rmses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "id": "d13uExUp8_0V",
    "outputId": "51d7d23f-4b38-4513-c3b6-1c3c0abb9e79"
   },
   "outputs": [],
   "source": [
    "pd.Series(tree_rmses).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Using the Decision Tree, the RMSE error for the entire training set is `13.3`, compared to an average of `39.2` for the cross-validation. This difference suggests that the Decision Tree model is *overfitted* and does not make good predictions.  Let's look at the depth and the number of leaves of our decision tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = tree_reg[-1].get_depth()\n",
    "n_leaves = tree_reg[-1].get_n_leaves()\n",
    "\n",
    "print(f'The depth of the decision tree is {depth} \\\n",
    "and the number of leaves is {n_leaves}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of leaves is roughly a third of the training set size, which may be too large. Let's use `max_depth` as a *hyperparameter* to tune the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_reg = make_pipeline(preprocessing, \n",
    "                         DecisionTreeRegressor(max_depth=10,\n",
    "                                               random_state=42))\n",
    "tree_reg.fit(compounds, bps)\n",
    "\n",
    "bp_predictions = tree_reg.predict(compounds)\n",
    "tree_rmse = root_mean_squared_error(bps, bp_predictions)\n",
    "tree_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_rmses = -cross_val_score(tree_reg, compounds, bps,\n",
    "                            scoring=\"neg_root_mean_squared_error\", cv=10)\n",
    "pd.Series(tree_rmses).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_fun(bps, bp_predictions, 'Decision Tree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Changing `max_depth` from `17` to `10` does not have a huge effect. **You can explore other values!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5CZ0nhC-8_0W"
   },
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Random Forest model performs multiple decision tree analyses on a subset of features and then chooses the best result. The size of the subset is typically $\\sqrt{n}$, where $n$ is the total number of features.  By compairing different subsets, the model can generate an indication of which features are most important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dOy_4P968_0X"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest_reg = make_pipeline(preprocessing,\n",
    "                       RandomForestRegressor(max_depth = 10, random_state=42))\n",
    "forest_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dOy_4P968_0X"
   },
   "outputs": [],
   "source": [
    "forest_reg.fit(compounds, bps)\n",
    "\n",
    "bp_predictions = forest_reg.predict(compounds)\n",
    "\n",
    "forest_rmses = -cross_val_score(forest_reg, compounds, bps,\n",
    "                            scoring=\"neg_root_mean_squared_error\", cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "id": "-t_ZPHTh8_0X",
    "outputId": "d8614e3d-7097-479d-d066-dbf66be9f5fb"
   },
   "outputs": [],
   "source": [
    "pd.Series(forest_rmses).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 499
    },
    "id": "yXZKtVNh8_0Y",
    "outputId": "c77fef16-ecdf-4396-d422-a6cdc457e121"
   },
   "outputs": [],
   "source": [
    "plot_fun(bps, bp_predictions, 'Random Forest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q4BaU3558_0Y"
   },
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZK5k7NtA8_0Y"
   },
   "outputs": [],
   "source": [
    "feature_importances = forest_reg['randomforestregressor'].feature_importances_\n",
    "feature_names = preprocessing.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "id": "SiuAV2GL8_0Z",
    "outputId": "b28fbcec-2cb1-4690-bcf1-20ab3a812c48"
   },
   "outputs": [],
   "source": [
    "barh(feature_names, feature_importances)\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Here we see that the molecular weight, `num_mw` is by far the most important feature. However, the polar area, carbon number and side chain number are also significant. The categories do not seem to be important at all.\n",
    "\n",
    "**Try reducing the number of features in the pipeline to see what affect that has on the results.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hapZBaww8_0Z"
   },
   "source": [
    "## Compare to Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DYoasxeV8_0a"
   },
   "outputs": [],
   "source": [
    "test_bps = test_set['BoilingPoint'].copy()\n",
    "test_predictions = forest_reg.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 499
    },
    "id": "z3bNg48J8_0a",
    "outputId": "8c214f24-442e-444b-a021-238fd5483b9a"
   },
   "outputs": [],
   "source": [
    "plot_fun(test_bps, test_predictions, 'Random Forest - Test Set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hBifLsPY8_0b",
    "outputId": "170fecf7-4237-4575-8bdd-a1c72180198d"
   },
   "outputs": [],
   "source": [
    "final_rmse = root_mean_squared_error(test_bps, test_predictions)\n",
    "print(final_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DFUSVTWr8_0e"
   },
   "source": [
    "---\n",
    "Now we finally compare our result to the test data and see that the predictions are ok but not great. We are off to a good start, but this model certainly could use some improvement.\n",
    "\n",
    "**What ideas do you have to improve this model, to the point that you would trust it for your work?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "hide_input": false,
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "nteract": {
   "version": "0.22.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
